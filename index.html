<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Alireza Mousavi-Hosseini</title>
</head>
<body>
<div id="layout-content">
<div id="toptitle">
<h1>Alireza Mousavi-Hosseini</h1>
</div>
<table class="imgtable"><tr><td>
<img src="photo.jpg" alt="288" width="246.8" />&nbsp;</td>
<td align="left"><p>Ph.D. Student,<br />
<a href="https://web.cs.toronto.edu/" target=&ldquo;blank&rdquo;>Department of Computer Science</a>,<br />
<a href="https://www.utoronto.ca/" target=&ldquo;blank&rdquo;>University of Toronto</a>,<br />
mousavi [@] cs (dot) toronto (dot) edu <br />
[<a href="CV.pdf" target=&ldquo;blank&rdquo;>CV</a>] [<a href="https://scholar.google.com/citations?user=D-xar0IAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a>]
</p>
</td></tr></table>
<h1>About me</h1>
<p>I am a computer science Ph.D. student at the University of Toronto and <a href="https://vectorinstitute.ai/" target=&ldquo;blank&rdquo;>Vector Institute</a>, advised by <a href="http://www.cs.toronto.edu/~erdogdu/" target=&ldquo;blank&rdquo;>Murat A. Erdogdu</a>. Before that, I received my B.Sc. in computer engineering from Sharif University of Technology. During Fall 2023, I visited <a href="https://lchizat.github.io/" target=&ldquo;blank&rdquo;>Lénaïc Chizat</a> at the EPFL Institute of Mathematics. During Summer 2025, I am interning at Apple ML Research with <a href="https://marcocuturi.net/" target=&ldquo;blank&rdquo;>Marco Cuturi</a>.
</p>
<h1>Research Interests</h1>
<p>I am broadly interested in statistical learning theory. At the moment, I am focusing on
</p>
<ul>
<li><p><u>Deep Learning Theory</u>: Provable comparisons between different architectures and training algorithms in terms of their <i>statistical</i> and <i>computational</i> efficiency.
</p>
</li>
<li><p><u>Non-convex Sampling and Generative Modeling</u>: Analysis of <i>flow models</i> and <i>diffusions</i> for generative modeling and non-log-concave sampling.
</p>
</li>
</ul>
<h1>Publications</h1>
<ul>
<li><p><a href="https://www.arxiv.org/abs/2506.05526" target=&ldquo;blank&rdquo;>On Fitting Flow Models with Large Sinkhorn Couplings</a><br />
Michal Klein, Alireza Mousavi-Hosseini, Stephen Zhang, Marco Cuturi.<br />
Preprint, 2025.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2503.11272" target=&ldquo;blank&rdquo;>When Do Transformers Outperform Feedforward and Recurrent Networks? A Statistical Perspective</a><br />
Alireza Mousavi-Hosseini, Clayton Sanford, Denny Wu, Murat A. Erdogdu.<br />
Preprint, 2025.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2410.16449" target=&ldquo;blank&rdquo;>Robust Feature Learning for Multi-Index Models in High Dimensions.</a><br />
Alireza Mousavi-Hosseini, Adel Javanmard, Murat A. Erdogdu.<br />
<b>ICLR 2025</b>, International Conference on Learning Representations.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2408.07254" target=&ldquo;blank&rdquo;>Learning Multi-Index Models with Neural Networks via Mean-Field Langevin Dynamics.</a><br />
Alireza Mousavi-Hosseini, Denny Wu, Murat A. Erdogdu.<br />
<b>ICLR 2025</b>, International Conference on Learning Representations.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2406.17054" target=&ldquo;blank&rdquo;>Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach.</a><br />
Guillaume Wang*, Alireza Mousavi-Hosseini*, Lénaïc Chizat.<br />
<b>NeurIPS 2024</b>, Advances in Neural Information Processing Systems. <b>(Spotlight)</b>
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2405.16736" target=&ldquo;blank&rdquo;>A Separation in Heavy-Tailed Sampling: Gaussian vs. Stable Oracles for Proximal Samplers.</a><br />
Ye He, Alireza Mousavi-Hosseini, Krishnakumar Balasubramanian, Murat A. Erdogdu.<br />
<b>NeurIPS 2024</b>, Advances in Neural Information Processing Systems.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2309.03843" target=&ldquo;blank&rdquo;>Gradient-Based Feature Learning under Structured Data.</a><br />
Alireza Mousavi-Hosseini, Denny Wu, Taiji Suzuki, Murat A. Erdogdu.<br />
<b>NeurIPS 2023</b>, Advances in Neural Information Processing Systems.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2303.03589" target=&ldquo;blank&rdquo;>Towards a Complete Analysis of Langevin Monte Carlo: Beyond Poincaré Inequality.</a><br />
Alireza Mousavi-Hosseini*, Tyler Farghly*, Ye He, Krishnakumar Balasubramanian, Murat A. Erdogdu.<br />
<b>COLT 2023</b>, Annual Conference on Learning Theory.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2209.14863" target=&ldquo;blank&rdquo;>Neural Networks Efficiently Learn Low-Dimensional Representations with SGD.</a><br />
Alireza Mousavi-Hosseini, Sejun Park, Manuela Girotti, Ioannis Mitliagkas, Murat A. Erdogdu.<br />
<b>ICLR 2023</b>, International Conference on Learning Representations. <b>(Spotlight)</b>
</p>
</li>
</ul>
<p><small>* Equal Contributions</small>
</p>
<h1>Miscellaneous</h1>
<ul>
<li><p>I am fascinated by the performing arts, old and modern theatres, and opera houses.











</p>
</li>
<li><p>UofT has an amazing theatre: <a href="https://harthouse.ca/theatre" target=&ldquo;blank&rdquo;>Hart House Theatre</a></p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-06-09, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</div>
</body>
</html>
